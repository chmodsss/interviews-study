# C03-S05: Business Analytics & Data Integration System

The small software and consulting company C3 developed S5, a system for big data analysis focused on data integration, data mining, and linguistic algorithms. The central backend consisted of six Microservices developed in a complete greenfield approach. We talked about its evolvability assurance process with architect P5 and lead developer P6. Coming from a very systematic background, P5 rated the process maturity as level 1 while P6 saw it as between level 1 and 2. However, both saw room for improvement and already had plans that were currently tested for a single GUI project. Confluence was used to document requirements, architecture, decisions, service communication, functionality, and dependencies. Additionally, some template projects for frequent components or services existed. The applied Git flow also prescribed mandatory code reviews to share knowledge and to increase quality. Overall, P5 said that quality would be very subjective at the moment without concrete principles and guidelines, but simplicity was seen as a key philosophy to avoid complexity (KISS principle). New functionality currently had a higher priority, even though they were aware that they needed to address quality soon. Even though some tools were installed, e.g. SonarQube with integrated FindBugs, Checkstyle, and PMD plugins, they were currently not really used. The integration of SonarQube into the CI/CD pipeline was planned though. Because of this, the only important metric currently was test coverage, even though there was no quality gate for it. Because RESTful inter-service communication was seen as not "clean" for 12-factor app Microservices, *Event-Driven Messaging* with Kafka was used to decouple services. Both P5 and P6 generally perceived the evolvability of S5 as positive (+1), but especially P5 saw some architectural shortcomings. Nonetheless, modularity and Microservices independence would ease development and accelerate releases. Assurance effectiveness was perceived as neutral (0) by P5 and as slightly negative (-1) by P6. Manual code review would be effective, but since not much tool support was used, much could be improved. Assurance influence on productivity was seen as positive (+1) by both, but in order to avoid and reduce accrued technical debt, more effort would be needed (P5: +2, P6: +1). In addition to the planned SonarQube instance, documented guidelines for code reviews, quality gates, automated end-to-end tests, as well as a more structured approach was seen as desirable. P5 also highlighted the importance of *defined* quality as opposed to *maximum* quality. As notable challenges, both P5 and P6 named mastering DevOps and Microservices technologies which would require a lot of efforts (e.g. Kubernetes). Moreover, some potentially harmful inter-service dependencies would still exist. The goal was to eliminate all unnecessary ones to achieve clean interface separations. Lastly, current quality views would be very service-centric without a holistic system perspective for comparisons. It would sometimes be difficult for developers to grasp the scope and responsibility of certain services, especially if they also worked on different projects.